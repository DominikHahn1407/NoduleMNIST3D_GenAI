{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef9f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import medmnist\n",
    "from medmnist import NoduleMNIST3D\n",
    "from utils import set_seet, ToTensor3D, SyntheticVAEDataset, train_classifier, evaluate_classifier, train_vae\n",
    "from cnn_architecture import CNN3D\n",
    "from genai_architecture import VAE3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89228157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d599c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = \"nodulemnist3d\"\n",
    "download = True\n",
    "batch_size = 64\n",
    "set_seet(42)\n",
    "\n",
    "transform = ToTensor3D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c36c43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 1158\n",
      "Val Size: 165\n",
      "Test size: 310\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NoduleMNIST3D(split=\"train\", transform=transform, download=download)\n",
    "val_dataset = NoduleMNIST3D(split=\"val\", transform=transform, download=download)\n",
    "test_dataset = NoduleMNIST3D(split=\"test\", transform=transform, download=download)\n",
    "\n",
    "print(\"Train Size:\", len(train_dataset))\n",
    "print(\"Val Size:\", len(val_dataset))\n",
    "print(\"Test size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed92ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da0ccd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training baseline classifier (no GenAI) ===\n",
      "[Epoch 01] Train Loss: 0.5390 Acc: 0.7539 | Val Loss: 0.6050 Acc: 43.1273\n",
      "[Epoch 02] Train Loss: 0.4700 Acc: 0.7832 | Val Loss: 0.5954 Acc: 43.0121\n",
      "[Epoch 03] Train Loss: 0.4365 Acc: 0.8083 | Val Loss: 0.5032 Acc: 40.9091\n",
      "[Epoch 04] Train Loss: 0.4162 Acc: 0.8161 | Val Loss: 0.6934 Acc: 24.1455\n",
      "[Epoch 05] Train Loss: 0.4286 Acc: 0.8212 | Val Loss: 0.4894 Acc: 34.5394\n",
      "[Epoch 06] Train Loss: 0.4182 Acc: 0.8143 | Val Loss: 0.4219 Acc: 39.6545\n",
      "[Epoch 07] Train Loss: 0.3962 Acc: 0.8273 | Val Loss: 0.4155 Acc: 39.0970\n",
      "[Epoch 08] Train Loss: 0.3963 Acc: 0.8247 | Val Loss: 0.7519 Acc: 22.9394\n",
      "[Epoch 09] Train Loss: 0.4106 Acc: 0.8230 | Val Loss: 0.4043 Acc: 38.8788\n",
      "[Epoch 10] Train Loss: 0.4032 Acc: 0.8290 | Val Loss: 0.4199 Acc: 38.1697\n",
      "[Epoch 11] Train Loss: 0.3992 Acc: 0.8195 | Val Loss: 0.4766 Acc: 40.6970\n",
      "[Epoch 12] Train Loss: 0.3782 Acc: 0.8472 | Val Loss: 0.7041 Acc: 41.2909\n",
      "[Epoch 13] Train Loss: 0.3943 Acc: 0.8377 | Val Loss: 0.4243 Acc: 37.9697\n",
      "[Epoch 14] Train Loss: 0.3920 Acc: 0.8351 | Val Loss: 0.3947 Acc: 37.5818\n",
      "[Epoch 15] Train Loss: 0.3861 Acc: 0.8359 | Val Loss: 0.7853 Acc: 41.0121\n",
      "[Epoch 16] Train Loss: 0.4016 Acc: 0.8299 | Val Loss: 0.3829 Acc: 38.2303\n",
      "[Epoch 17] Train Loss: 0.3848 Acc: 0.8497 | Val Loss: 0.4202 Acc: 39.4242\n",
      "[Epoch 18] Train Loss: 0.3672 Acc: 0.8446 | Val Loss: 0.3996 Acc: 38.6606\n",
      "[Epoch 19] Train Loss: 0.3621 Acc: 0.8351 | Val Loss: 0.4537 Acc: 34.2182\n",
      "[Epoch 20] Train Loss: 0.3671 Acc: 0.8463 | Val Loss: 0.5334 Acc: 40.3212\n",
      "[Epoch 21] Train Loss: 0.3547 Acc: 0.8592 | Val Loss: 0.3923 Acc: 36.7091\n",
      "[Epoch 22] Train Loss: 0.3773 Acc: 0.8351 | Val Loss: 0.8281 Acc: 41.4485\n",
      "[Epoch 23] Train Loss: 0.3665 Acc: 0.8428 | Val Loss: 0.3735 Acc: 38.9939\n",
      "[Epoch 24] Train Loss: 0.3536 Acc: 0.8532 | Val Loss: 0.3904 Acc: 38.6606\n",
      "[Epoch 25] Train Loss: 0.3565 Acc: 0.8541 | Val Loss: 0.4026 Acc: 37.1818\n",
      "[Epoch 26] Train Loss: 0.3461 Acc: 0.8541 | Val Loss: 0.5342 Acc: 39.6545\n",
      "[Epoch 27] Train Loss: 0.3504 Acc: 0.8532 | Val Loss: 0.3750 Acc: 39.1091\n",
      "[Epoch 28] Train Loss: 0.3352 Acc: 0.8627 | Val Loss: 0.4239 Acc: 39.3394\n",
      "[Epoch 29] Train Loss: 0.3535 Acc: 0.8515 | Val Loss: 0.3463 Acc: 37.7394\n",
      "[Epoch 30] Train Loss: 0.3362 Acc: 0.8618 | Val Loss: 0.4163 Acc: 36.7636\n",
      "Baseline Test Acc: 49.4645\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Training baseline classifier (no GenAI) ===\")\n",
    "baseline_model = CNN3D(num_classes=2)\n",
    "baseline_model, baseline_val_acc = train_classifier(\n",
    "    model=baseline_model,\n",
    "    device=device,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=30\n",
    ")\n",
    "baseline_test_acc, _ = evaluate_classifier(baseline_model, device, test_loader)\n",
    "print(f\"Baseline Test Acc: {baseline_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf6d338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training 3D VAE (GenAI) on nodules ===\n",
      "[VAE Epoch 01] Loss: 18540.1284\n",
      "[VAE Epoch 02] Loss: 11283.6282\n",
      "[VAE Epoch 03] Loss: 11274.8632\n",
      "[VAE Epoch 04] Loss: 11273.5960\n",
      "[VAE Epoch 05] Loss: 11272.3972\n",
      "[VAE Epoch 06] Loss: 11272.0250\n",
      "[VAE Epoch 07] Loss: 11278.5184\n",
      "[VAE Epoch 08] Loss: 11271.7751\n",
      "[VAE Epoch 09] Loss: 11272.0153\n",
      "[VAE Epoch 10] Loss: 11277.5482\n",
      "[VAE Epoch 11] Loss: 11275.8354\n",
      "[VAE Epoch 12] Loss: 11273.2453\n",
      "[VAE Epoch 13] Loss: 11271.2042\n",
      "[VAE Epoch 14] Loss: 11272.7120\n",
      "[VAE Epoch 15] Loss: 11272.3623\n",
      "[VAE Epoch 16] Loss: 11271.0447\n",
      "[VAE Epoch 17] Loss: 11276.4660\n",
      "[VAE Epoch 18] Loss: 11272.4534\n",
      "[VAE Epoch 19] Loss: 11271.7535\n",
      "[VAE Epoch 20] Loss: 11270.9862\n",
      "[VAE Epoch 21] Loss: 11270.0983\n",
      "[VAE Epoch 22] Loss: 11269.7990\n",
      "[VAE Epoch 23] Loss: 11273.2150\n",
      "[VAE Epoch 24] Loss: 11274.2627\n",
      "[VAE Epoch 25] Loss: 11271.9031\n",
      "[VAE Epoch 26] Loss: 11269.9094\n",
      "[VAE Epoch 27] Loss: 11276.6574\n",
      "[VAE Epoch 28] Loss: 11273.1808\n",
      "[VAE Epoch 29] Loss: 11270.1599\n",
      "[VAE Epoch 30] Loss: 11269.6382\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Training 3D VAE (GenAI) on nodules ===\")\n",
    "vae = VAE3D(latent_dim=64)\n",
    "vae = train_vae(vae, device, train_loader, epochs=30, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55da25f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in train set: [863 295] -> probs: [0.74525043 0.25474957]\n"
     ]
    }
   ],
   "source": [
    "labels = [train_dataset[i][1].item() for i in range(len(train_dataset))]\n",
    "labels = np.array(labels)\n",
    "num_classes = 2\n",
    "counts = np.bincount(labels, minlength=num_classes)\n",
    "label_probs = counts / counts.sum()\n",
    "print(\"Label distribution in train set:\", counts, \"-> probs:\", label_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c810854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_synthetic = len(train_dataset)  # e.g. 1x the real data size\n",
    "synthetic_dataset = SyntheticVAEDataset(vae, device, length=num_synthetic,\n",
    "                                        label_probs=label_probs,\n",
    "                                        num_classes=num_classes)\n",
    "\n",
    "augmented_train_dataset = ConcatDataset([train_dataset, synthetic_dataset])\n",
    "aug_train_loader = DataLoader(augmented_train_dataset, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df73a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training classifier with GenAI-augmented data ===\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n    ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 269, in collate_tensor_fn\n    numel = sum(x.numel() for x in batch)\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 269, in <genexpr>\n    numel = sum(x.numel() for x in batch)\n                ^^^^^^^\nAttributeError: 'numpy.ndarray' object has no attribute 'numel'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Training classifier with GenAI-augmented data ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m genai_model \u001b[38;5;241m=\u001b[39m CNN3D(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m genai_model, genai_val_acc \u001b[38;5;241m=\u001b[39m train_classifier(\n\u001b[0;32m      4\u001b[0m     genai_model,\n\u001b[0;32m      5\u001b[0m     device,\n\u001b[0;32m      6\u001b[0m     aug_train_loader,\n\u001b[0;32m      7\u001b[0m     val_loader,\n\u001b[0;32m      8\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m      9\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m genai_test_acc, _ \u001b[38;5;241m=\u001b[39m evaluate_classifier(genai_model, device, test_loader)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenAI-Augmented Test Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenai_test_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\Documents\\GitHub\\NoduleMNIST3D_GenAI\\utils.py:63\u001b[0m, in \u001b[0;36mtrain_classifier\u001b[1;34m(model, device, train_loader, val_loader, epochs, lr)\u001b[0m\n\u001b[0;32m     60\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     61\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     64\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     65\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    738\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1506\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1504\u001b[0m worker_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(idx)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1541\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data, worker_idx)\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1541\u001b[0m     data\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\_utils.py:769\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 769\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n    ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 269, in collate_tensor_fn\n    numel = sum(x.numel() for x in batch)\n  File \"c:\\Users\\Dominik Hahn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 269, in <genexpr>\n    numel = sum(x.numel() for x in batch)\n                ^^^^^^^\nAttributeError: 'numpy.ndarray' object has no attribute 'numel'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Training classifier with GenAI-augmented data ===\")\n",
    "genai_model = CNN3D(num_classes=2)\n",
    "genai_model, genai_val_acc = train_classifier(\n",
    "    genai_model,\n",
    "    device,\n",
    "    aug_train_loader,\n",
    "    val_loader,\n",
    "    epochs=30,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "genai_test_acc, _ = evaluate_classifier(genai_model, device, test_loader)\n",
    "print(f\"GenAI-Augmented Test Acc: {genai_test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
